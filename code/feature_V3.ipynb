{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# # SKlearn classification models\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "#cross validation\n",
    "from scipy import sparse\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "uid_train = pd.read_csv('../data/uid_train.txt',sep='\\t',header=None,names=('uid','label'))\n",
    "voice_train = pd.read_csv('../data/voice_train.txt',sep='\\t',header=None,names=('uid','opp_num','opp_head','opp_len','start_time','end_time','call_type','in_out'),dtype={'start_time':str,'end_time':str},encoding='utf-8')\n",
    "sms_train = pd.read_csv('../data/sms_train.txt',sep='\\t',header=None,names=('uid','opp_num','opp_head','opp_len','start_time','in_out'),dtype={'start_time':str},encoding='utf-8')\n",
    "wa_train = pd.read_csv('../data/wa_train.txt',sep='\\t',header=None,names=('uid','wa_name','visit_cnt','visit_dura','up_flow','down_flow','wa_type','date'),dtype={'date':str},encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_test = pd.read_csv('../data/voice_test_b.txt',sep='\\t',header=None,names=('uid','opp_num','opp_head','opp_len','start_time','end_time','call_type','in_out'),dtype={'start_time':str,'end_time':str},encoding='utf-8')\n",
    "sms_test = pd.read_csv('../data/sms_test_b.txt',sep='\\t',header=None,names=('uid','opp_num','opp_head','opp_len','start_time','in_out'),dtype={'start_time':str},encoding='utf-8')\n",
    "wa_test = pd.read_csv('../data/wa_test_b.txt',sep='\\t',header=None,names=('uid','wa_name','visit_cnt','visit_dura','up_flow','down_flow','wa_type','date'),dtype={'date':str},encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_test_a = pd.read_csv('../data/voice_test_a.txt',sep='\\t',header=None,names=('uid','opp_num','opp_head','opp_len','start_time','end_time','call_type','in_out'),dtype={'start_time':str,'end_time':str},encoding='utf-8')\n",
    "sms_test_a = pd.read_csv('../data/sms_test_a.txt',sep='\\t',header=None,names=('uid','opp_num','opp_head','opp_len','start_time','in_out'),dtype={'start_time':str},encoding='utf-8')\n",
    "wa_test_a = pd.read_csv('../data/wa_test_a.txt',sep='\\t',header=None,names=('uid','wa_name','visit_cnt','visit_dura','up_flow','down_flow','wa_type','date'),dtype={'date':str},encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_test = pd.DataFrame({'uid':pd.unique(wa_test['uid'])})\n",
    "\n",
    "voice = pd.concat([voice_train,voice_test_a,voice_test],axis=0)\n",
    "sms = pd.concat([sms_train,sms_test_a,sms_test],axis=0)\n",
    "wa = pd.concat([wa_train,wa_test_a,wa_test],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_test = pd.DataFrame({'uid':pd.unique(wa_test['uid'])})\n",
    "uid_test.to_csv('../data/uid_test_b.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice.drop_duplicates(inplace=True)\n",
    "sms.drop_duplicates(inplace=True)\n",
    "wa.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_groupby(data,groupby_col,count_col,methods,prefix,fill=None):\n",
    "    temp = data.groupby([groupby_col])[count_col].agg(methods).add_prefix(prefix).reset_index()\n",
    "    if fill !=None:\n",
    "        temp.fillna(fill,inplace=True)\n",
    "    return temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 通话记录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 通话记录不同记录数 通话记录数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "voice_opp_num = single_groupby(voice,'uid','opp_num',{'unique_count': lambda x: len(pd.unique(x)),'count':'count'},'voice_opp_num_',0)\n",
    "voice_opp_head = single_groupby(voice,'uid','opp_head',{'unique_count': lambda x: len(pd.unique(x))},'voice_opp_head_',0)\n",
    "\n",
    "voice_opp_len=voice.groupby(['uid','opp_len'])['uid'].count().unstack().add_prefix('voice_opp_len_').reset_index().fillna(0)\n",
    "voice_opp_len_opp_num_unique=voice.groupby(['uid','opp_len'])['opp_num'].agg(lambda x: len(pd.unique(x))).unstack().add_prefix('voice_opp_len_opp_num_unique_').reset_index().fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "voice_call_type = voice.groupby(['uid','call_type'])['uid'].count().unstack().add_prefix('voice_call_type_').reset_index().fillna(0)\n",
    "voice_call_type_opp_num_unique=voice.groupby(['uid','call_type'])['opp_num'].agg(lambda x: len(pd.unique(x))).unstack().add_prefix('voice_call_type_opp_num_unique_').reset_index().fillna(0)\n",
    "\n",
    "voice_in_out_opp_num_unique = voice.groupby(['uid','in_out'])['opp_num'].agg(lambda x: len(pd.unique(x))).unstack().add_prefix('voice_in_out_opp_num_unique_').reset_index().fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_each_opp_head_count=voice.groupby(['uid','opp_head'])['uid'].count().unstack().add_prefix('voice_each_opp_head_count_').reset_index().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_opp_len_opp_head_unique=voice.groupby(['uid','opp_len'])['opp_head'].agg(lambda x: len(pd.unique(x))).unstack().add_prefix('voice_opp_len_opp_head_unique_').reset_index().fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opp_num_list = voice.groupby(['opp_num'])['uid'].count().sort_values(ascending=False).reset_index()['opp_num'][0:1000].values\n",
    "voice_each_opp_num_count=voice[voice.opp_num.map(lambda x: x in opp_num_list)].groupby(['uid','opp_num'])['uid'].count().unstack().add_prefix('voice_each_opp_num_count_').reset_index().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_gap(start,end):\n",
    "    if pd.isnull(start):\n",
    "        return np.nan\n",
    "    end_day = int(str(end)[0:2])\n",
    "    start_day = int(str(start)[0:2])\n",
    "    day_gap = (end_day-start_day)*86400\n",
    "    \n",
    "    \n",
    "    end_hour = int(str(end)[2:4])\n",
    "    start_hour = int(str(start)[2:4])\n",
    "    hour_gap = (end_hour-start_hour)*3600\n",
    "    \n",
    "    \n",
    "    \n",
    "    end_min = int(str(end)[4:6])\n",
    "    start_min = int(str(start)[4:6])\n",
    "    min_gap = (end_min-start_min)*60\n",
    "    \n",
    "    \n",
    "    end_sec = int(str(end)[6:8])\n",
    "    start_sec = int(str(start)[6:8])\n",
    "    sec_gap = (end_sec-start_sec)\n",
    "    \n",
    "    \n",
    "    return day_gap+hour_gap+min_gap+sec_gap\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 通话时长统计\n",
    "voice['gap_time']=voice[['start_time','end_time']].apply(lambda x: time_gap(x[0],x[1]),axis=1)\n",
    "\n",
    "voice_gap_time=voice.groupby(['uid'])['gap_time'].agg(['std','max','min','median','mean','sum',np.ptp]).add_prefix('voice_gap_time_').reset_index()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  通话时间间隔统计\n",
    "voice_sort = (voice.sort_values(by=['start_time','end_time'],ascending=True)).reset_index()\n",
    "voice_sort['last_end_time']=voice_sort.groupby(['uid'])['end_time'].apply(lambda i:i.shift(1))\n",
    "voice_sort['last_gap_time'] = voice_sort[['last_end_time','start_time']].apply(lambda x: time_gap(x[0],x[1]),axis=1)\n",
    "\n",
    "\n",
    "voice_last_gap_time=voice_sort.groupby(['uid'])['last_gap_time'].agg(['std','max','min','median','mean','sum',np.ptp]).add_prefix('voice_last_gap_time_').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice['start_day']=voice.start_time.map(lambda x: x[0:2])\n",
    "voice['end_day']=voice.end_time.map(lambda x: x[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_start_day_count = voice.groupby(['uid','start_day'])['opp_head'].agg(lambda x: len(pd.unique(x))).unstack().fillna(0).add_prefix('voice_start_day_count_').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_opp_num = sms.groupby(['uid'])['opp_num'].agg({'unique_count': lambda x: len(pd.unique(x)),'count':'count'}).add_prefix('sms_opp_num_').reset_index().fillna(0)\n",
    "sms_opp_head=sms.groupby(['uid'])['opp_head'].agg({'unique_count': lambda x: len(pd.unique(x))}).add_prefix('sms_opp_head_').reset_index().fillna(0)\n",
    "sms_opp_len=sms.groupby(['uid','opp_len'])['uid'].count().unstack().add_prefix('sms_opp_len_').reset_index().fillna(0)\n",
    "\n",
    "sms_opp_len_opp_head_unique=sms.groupby(['uid','opp_len'])['opp_head'].agg(lambda x: len(pd.unique(x))).unstack().add_prefix('sms_opp_len_opp_head_unique_').reset_index().fillna(0)\n",
    "\n",
    "\n",
    "sms_in_out = sms.groupby(['uid','in_out'])['uid'].count().unstack().add_prefix('sms_in_out_').reset_index().fillna(0)\n",
    "\n",
    "\n",
    "sms_in_out['sms_in_out_0_rate'] = sms_in_out['sms_in_out_0'] / sms_opp_num['sms_opp_num_count']\n",
    "\n",
    "sms_in_out['sms_in_out_1_rate'] = sms_in_out['sms_in_out_1'] / sms_opp_num['sms_opp_num_count']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in sms_opp_len.columns:\n",
    "#     if col !='uid':\n",
    "#         sms_opp_len[col+'_rate'] = sms_opp_len[col] /  sms_opp_num['sms_opp_num_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms['hour'] = sms.start_time.map(lambda x: x[2:4])\n",
    "sms['day'] = sms.start_time.map(lambda x: x[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "opp_len = [5,7,8,9,10,11,12,13,14]\n",
    "sms_opp_count = []\n",
    "for l in opp_len:\n",
    "    temp = sms[sms.opp_len==l].groupby(['uid','hour'])['uid'].count().unstack().add_prefix('sms_hour_count_opp_len_'+str(l)+'_').reset_index().fillna(0)\n",
    "    sms_opp_count.append(temp)\n",
    "    \n",
    "for l in opp_len:\n",
    "    temp = sms[sms.opp_len==l].groupby(['uid','day'])['uid'].count().unstack().add_prefix('sms_day_count_opp_len_'+str(l)+'_').reset_index().fillna(0)\n",
    "    sms_opp_count.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_each_opp_head_count=sms.groupby(['uid','opp_head'])['uid'].count().unstack().add_prefix('sms_each_opp_head_count_').reset_index().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sms_opp_num_list = sms.groupby(['opp_num'])['uid'].count().sort_values(ascending=False).reset_index()['opp_num'][0:1000].values\n",
    "sms_each_opp_num_count=sms[sms.opp_num.map(lambda x: x in sms_opp_num_list)].groupby(['uid','opp_num'])['uid'].count().unstack().add_prefix('sms_each_opp_num_count_').reset_index().fillna(0)\n",
    "\n",
    "\n",
    "#sms_each_opp_num_count=sms.groupby(['uid','opp_num'])['uid'].count().unstack().add_prefix('sms_each_opp_num_count_').reset_index().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  短信间隔统计\n",
    "sms_sort = sms.sort_values(by=['uid','start_time'],ascending='True').reset_index()\n",
    "sms_sort['last_start_time']=sms_sort.groupby(['uid'])['start_time'].apply(lambda i:i.shift(1))\n",
    "sms_sort['last_start_gap_time'] = sms_sort[['last_start_time','start_time']].apply(lambda x: time_gap(x[0],x[1]),axis=1)\n",
    "sms_last_start_gap_time=sms_sort.groupby(['uid'])['last_start_gap_time'].agg(['std','max','min','median','mean','sum',np.ptp]).add_prefix('sms_last_start_gap_time_').reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_each_day_count = sms.groupby(['uid','day'])['opp_num'].count().unstack().fillna(0).add_prefix('sms_each_day_count_').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_each_day_unique_count_opp_head = sms.groupby(['uid','day'])['opp_head'].agg(lambda x: len(pd.unique(x))).unstack().fillna(0).add_prefix('sms_each_day_unique_count_opp_head_').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_each_day_unique_count_opp_num = sms.groupby(['uid','day'])['opp_num'].agg(lambda x: len(pd.unique(x))).unstack().fillna(0).add_prefix('sms_each_day_unique_count_opp_num_').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_each_day_in_out_0_count = sms[sms.in_out==0].groupby(['uid','day'])['uid'].count().unstack().fillna(0).add_prefix('sms_each_day_in_out_0_count_').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_each_day_in_out_1_count = sms[sms.in_out==1].groupby(['uid','day'])['uid'].count().unstack().fillna(0).add_prefix('sms_each_day_in_out_1_count_').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_each_hour_unique_count_opp_head = sms.groupby(['uid','hour'])['opp_head'].agg(lambda x: len(pd.unique(x))).unstack().fillna(0).add_prefix('sms_each_hour_unique_count_opp_head_').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_each_hour_unique_count_opp_num = sms.groupby(['uid','hour'])['opp_num'].agg(lambda x: len(pd.unique(x))).unstack().fillna(0).add_prefix('sms_each_hour_unique_count_opp_num_').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "sms_in_out_opp_num_unique = sms.groupby(['uid','in_out'])['opp_num'].agg(lambda x: len(pd.unique(x))).unstack().add_prefix('sms_in_out_opp_num_unique_').reset_index().fillna(0)\n",
    "sms_in_out_opp_head_unique = sms.groupby(['uid','in_out'])['opp_head'].agg(lambda x: len(pd.unique(x))).unstack().add_prefix('sms_in_out_opp_head_unique_').reset_index().fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网站/app记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa_a = pd.concat([wa_train,wa_test_a],axis=0)\n",
    "\n",
    "wa_name_list = wa.groupby(['wa_name'])['uid'].count().sort_values(ascending=False).reset_index()['wa_name'][0:1000].values\n",
    "wa_each_name_count=wa[wa.wa_name.map(lambda x: x in wa_name_list)].groupby(['uid','wa_name'])['uid'].count().unstack().add_prefix('wa_each_name_count_').reset_index().fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_feature = [voice_opp_num,  ## 统计用户 记录数，用户 不同opp_num 记录数\n",
    "                 voice_opp_head, ## 统计用户不同 opp_head记录 数\n",
    "           voice_opp_len,  ## 统计用户 不同 opp_len 的记录数\n",
    "           voice_call_type, ## 统计用户不同 call_tyoe 记录数\n",
    "           voice_in_out_opp_num_unique, ## 统计用户不同  in_out 下 不同 opp_num记录数\n",
    "           voice_opp_len_opp_num_unique, ## 统计不同 opp_len 下 不同 opp_head 记录数\n",
    "            voice_opp_len_opp_head_unique, ## 统计不同 opp_len 下不同opp_head 的记录数\n",
    "            voice_call_type_opp_num_unique,  ## 统计不同call_type 下 不同opp_num 的记录数\n",
    "          voice_gap_time,  ## 通话时长统计量\n",
    "          voice_last_gap_time, ## 两次通话间隔统计量\n",
    "        voice_each_opp_num_count, ## 对opp_num one-hot 统计记录数\n",
    "                 \n",
    "\n",
    "                ]\n",
    "\n",
    "\n",
    "sms_feature = [sms_opp_num,  ## 统计用户sms 不同opp_num记录数\n",
    "              sms_opp_head, ## 统计用户sms 不同opp_head 记录数\n",
    "              sms_opp_len, ##统计用户 不同opp_len记录数\n",
    "              sms_opp_len_opp_head_unique, ##统计用户不同opp_len 中 不同opp_head的记录数\n",
    "              sms_in_out, ## 不同in_out 记录数\n",
    "              sms_last_start_gap_time, ## 两次短信间隔统计量\n",
    "               sms_each_day_count, ##每天的短信记录数\n",
    "               sms_each_day_unique_count_opp_head, ## 每天不同的opp_head 记录数\n",
    "               \n",
    "                sms_in_out_opp_head_unique, ## 不同in_out 下 不同opp_head 数\n",
    "\n",
    "                sms_each_opp_head_count, ## opp_head one-hot 统计记录数\n",
    "    \n",
    "               \n",
    "               \n",
    "               \n",
    "\n",
    "               \n",
    "              ]\n",
    "#sms_feature =sms_feature+sms_opp_count\n",
    "\n",
    "wa_feature = [\n",
    "\n",
    "    \n",
    "    wa_each_name_count, ##top 1000 wa_name 分组统计记录数\n",
    "\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = uid_train\n",
    "test_feature = uid_test\n",
    "\n",
    "for feat in voice_feature:\n",
    "    train_feature=pd.merge(train_feature,feat,how='left',on='uid')\n",
    "for feat in voice_feature:\n",
    "    test_feature=pd.merge(test_feature,feat,how='left',on='uid')\n",
    "    \n",
    "for feat in sms_feature:\n",
    "    train_feature=pd.merge(train_feature,feat,how='left',on='uid')\n",
    "for feat in sms_feature:\n",
    "    test_feature=pd.merge(test_feature,feat,how='left',on='uid')\n",
    "    \n",
    "for feat in wa_feature:\n",
    "    train_feature=pd.merge(train_feature,feat,how='left',on='uid')\n",
    "for feat in wa_feature:\n",
    "    test_feature=pd.merge(test_feature,feat,how='left',on='uid')\n",
    "    \n",
    "for feat in voice_sms_feature:\n",
    "    train_feature=pd.merge(train_feature,feat,how='left',on='uid')\n",
    "for feat in voice_sms_feature:\n",
    "    test_feature=pd.merge(test_feature,feat,how='left',on='uid')\n",
    "    \n",
    "# train_feature=pd.merge(train_feature,stacking_feat[stacking_col],how='left',on='uid')\n",
    "# test_feature=pd.merge(test_feature,stacking_feat[stacking_col],how='left',on='uid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature.to_csv('../data/train_featureV0.csv',index=None,encoding='utf-8')\n",
    "test_feature.to_csv('../data/test_featureV0.csv',index=None,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4999, 2315)\n"
     ]
    }
   ],
   "source": [
    "print train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
